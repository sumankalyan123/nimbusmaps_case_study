{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "71394eb4-6e2b-4f18-ba6a-fbcaa48608d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UID: decimal(38,0) (nullable = false)\n",
      " |-- ADDRESS: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- ZIPCODE: string (nullable = true)\n",
      " |-- DECISION: string (nullable = true)\n",
      " |-- CREATE_TS: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, LongType, IntegerType\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "spark = (SparkSession\n",
    ".builder\n",
    ".master('local')\n",
    ".appName('wiki-changes-event-consumer')\n",
    "# Add kafka package\n",
    ".config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,net.snowflake:spark-snowflake_2.12:2.10.0-spark_3.2\")\n",
    ".getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "\n",
    "sfOptions = {\n",
    " \"sfURL\" : \"zu02863.ap-south-1.aws.snowflakecomputing.com\",\n",
    " \"sfAccount\" : \"zu02863.ap-south-1.aws\",\n",
    " \"sfUser\" : \"coolkeonjhar\",\n",
    " \"sfPassword\" : \"Amrita@123\",\n",
    " \"sfDatabase\" : \"NIMBUS_MAPS\",\n",
    " \"sfSchema\" : \"RAW_LAYER\",\n",
    " \"sfWarehouse\" : \"compute_wh\",\n",
    " \"sfRole\" : \"ACCOUNTADMIN\"\n",
    "}\n",
    " \n",
    "    \n",
    "df = spark.read.format('snowflake') \\\n",
    "  .options(**sfOptions) \\\n",
    "  .option(\"query\",  \"select UID,ADDRESS,CITY,ZIPCODE,DECISION,CURRENT_TIMESTAMP() AS CREATE_TS from NIMBUS_MAPS.STAGING_DATA_LAKE.DECISION_DATA_STG where create_ts >(select nvl(max(CREATE_TS),to_timestamp('2001-01-01 00:00:00','YYYY-MM-DD HH24:MI:SS')) FROM NIMBUS_MAPS.RAW_LAYER.DECISION_DATA_RAW)\") \\\n",
    "  .load()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "96cf06ef-9804-4835-8efb-cbb473713e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3de79d20-a5d6-496f-834b-8c6a1cf90b32",
   "metadata": {},
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae12b82e-5e50-41e1-8ca8-a7045c379e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16903803-886c-4080-a6d2-c1a1d245c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it has 1 duplicates\n"
     ]
    }
   ],
   "source": [
    "duplicates_count=df_dupli.count()\n",
    "if duplicates_count>0:\n",
    "    print(f'it has {duplicates_count} duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e48af9e6-c4fe-40c4-b48d-80d100df7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format(SNOWFLAKE_SOURCE_NAME).options(**sfOptions).option(\"dbtable\", \"NIMBUS_MAPS.RAW_LAYER.DECISION_DATA_RAW\").mode(\"append\").options(header=True).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1cef543d-8283-47e3-8cd5-4cbdfdcaff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-------+--------+--------------------+-----+\n",
      "|    UID|             ADDRESS|     CITY|ZIPCODE|DECISION|           CREATE_TS|count|\n",
      "+-------+--------------------+---------+-------+--------+--------------------+-----+\n",
      "|8902048|3808 Joseph Forge...|Ceciliano|  33562|       C|+0530 2022-02-27 ...|    2|\n",
      "+-------+--------------------+---------+-------+--------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dupli.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6dd5dc6e-6458-4dd7-b02c-90a7fb538e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_dupli.select('UID','CREATE_TS').write.format(SNOWFLAKE_SOURCE_NAME).options(**sfOptions).option(\"dbtable\", \"NIMBUS_MAPS.RAW_LAYER.log_duplicates\").mode(\"append\").options(header=True).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "428e4c89-a7b1-4447-982b-4fb054959f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UID: decimal(38,0)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a089db9c-5fb1-4e0f-8f19-9abcbe2d7141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing count\n",
      "4555\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "import time\n",
    "import json\n",
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n",
    "\n",
    "spark = (SparkSession\n",
    ".builder\n",
    ".master('local')\n",
    ".appName('wiki-changes-event-consumer')\n",
    "# Add kafka package\n",
    ".config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,net.snowflake:spark-snowflake_2.12:2.10.0-spark_3.2\")\n",
    ".getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "\n",
    "sfOptions = {\n",
    " \"sfURL\" : \"zu02863.ap-south-1.aws.snowflakecomputing.com\",\n",
    " \"sfAccount\" : \"zu02863.ap-south-1.aws\",\n",
    " \"sfUser\" : \"coolkeonjhar\",\n",
    " \"sfPassword\" : \"Amrita@123\",\n",
    " \"sfDatabase\" : \"NIMBUS_MAPS\",\n",
    " \"sfSchema\" : \"RAW_LAYER\",\n",
    " \"sfWarehouse\" : \"compute_wh\",\n",
    " \"sfRole\" : \"ACCOUNTADMIN\"\n",
    "}\n",
    " \n",
    "    \n",
    "df = spark.read.format('snowflake') \\\n",
    "  .options(**sfOptions) \\\n",
    "  .option(\"query\",  \"select UID,ADDRESS,CITY,ZIPCODE,DECISION,CURRENT_TIMESTAMP() AS CREATE_TS from NIMBUS_MAPS.RAW_LAYER.DECISION_DATA_RAW where create_ts >(select nvl(max(CREATE_TS),to_timestamp('2001-01-01 00:00:00','YYYY-MM-DD HH24:MI:SS')) FROM nimbus_maps.presentation.decision_data_pres)\") \\\n",
    "  .load()\n",
    "\n",
    "print('printing count')\n",
    "print(df.count())\n",
    "\n",
    "if df.count()==0:\n",
    "    print('No data to process')\n",
    "    sc.stop()\n",
    "    quit()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b2f31-b255-4e72-977e-9159e5e4c82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a6952a3e-a4a4-442d-ab1d-9c52ee8edae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGoodDecision(decision):\n",
    "    verdict = ''\n",
    "    if decision.upper()=='A':\n",
    "        verdict=True\n",
    "    else:\n",
    "        verdict=False\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "42b75d7a-5e00-4426-b7ba-a55f6497db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           create_ts|\n",
      "+--------------------+\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "|+0530 2022-02-27 ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select('create_ts').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9be15e59-a9ba-41d6-9c44-597d65d9c4a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: <function isGoodDecision at 0x7f13261791f0> of type <class 'function'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69792/2706623895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mudfsomefunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misGoodDecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"isGoodDecision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudfsomefunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DECISION\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DECISION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'isGoodDecision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'create_ts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[0mConverts\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlower\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m     \"\"\"\n\u001b[0;32m-> 2582\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function_over_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lower\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_invoke_function_over_column\u001b[0;34m(name, col)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;34m\"Invalid argument, not a string or column: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m\"{0} of type {1}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: <function isGoodDecision at 0x7f13261791f0> of type <class 'function'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "udfsomefunc = F.lower(F.udf(isGoodDecision, StringType()))\n",
    "df3 = df.withColumn(\"isGoodDecision\", udfsomefunc(\"DECISION\"))\n",
    "df4 = df3.select('UID','DECISION','isGoodDecision','create_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7ec060d0-6c3c-4463-91fb-d2b8ebc5eb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UID: decimal(38,0), DECISION: string, isGoodDecision: string, create_ts: timestamp]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df53ee7-154b-4eb4-8a58-b012c8136045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "38ddee23-d579-4c98-9dbc-2257cbef3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger= spark._jvm.org.apache.log4j.Logger\n",
    "mylogger = Logger.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "15a679d0-c757-4605-b8a9-51e822c097f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylogger.info(\"some info trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33580c-6ab7-4503-abd1-0879dbe79358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d7421-6293-4abd-b628-d2dabaca7784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
